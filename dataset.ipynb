{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create my own dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LIBRARIES ###\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import openai\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import pdfkit\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "from user_agent import generate_user_agent\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
    "from pdfminer.high_level import extract_text\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_embedding(content, model_name):\n",
    "    '''\n",
    "    generating embedding for model\n",
    "    '''\n",
    "    #Load the model\n",
    "    # model = SentenceTransformer('sentence-transformers/' + model_name)\n",
    "    model = SentenceTransformer(model_name,)\n",
    "\n",
    "    embeddings = model.encode(content)\n",
    "    return embeddings\n",
    "\n",
    "mymodel = '/Users/slidarey/Downloads/rbc-demo/90000'\n",
    "\n",
    "def split_into_sentences(content, no_sntcs=4):\n",
    "    '''\n",
    "    This function splits the text into sentences and then groups them into desired number of sentences.\n",
    "    :param content: text to be split\n",
    "    :param no_sntcs: number of sentences to be grouped\n",
    "    :param split_overlap: if True, then the sentences will be split with overlap\n",
    "    :param no_of_tokens: number of tokens to be grouped\n",
    "    :param overlap: number of sentences to be overlapped\n",
    "    :return: list of dictionaries with grouped sentences\n",
    "    '''\n",
    "    sentences = re.split('\\.\\s([A-Z][\\w\\d]+)', content)\n",
    "    clnd_sntc = list()\n",
    "    grpd_sntc = list()\n",
    "\n",
    "    # splitting the whole text into sentences\n",
    "    for i in range(len(sentences)):\n",
    "        if i == 0:\n",
    "            # first sentence\n",
    "            clnd_sntc.append(sentences[i].strip() + '.')\n",
    "        elif (i+2 == len(sentences)):\n",
    "\n",
    "            # for last sentence = appending captured split pattern to it's sentence\n",
    "            clnd_sntc.append((sentences[i] + sentences[i+1]).strip())\n",
    "        elif ((i % 2) != 0):\n",
    "\n",
    "            # for middle sentences - appending captured split pattern to it's sentence\n",
    "            clnd_sntc.append(sentences[i] + sentences[i+1] + '.')\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    # check if number of sentences is more than the desired number of sentences for grouping\n",
    "    if len(clnd_sntc) >= no_sntcs:\n",
    "\n",
    "        # to know how many group of sentences can be formed\n",
    "        for i in range(len(clnd_sntc)//no_sntcs):\n",
    "\n",
    "            # group and append desired set of sentences\n",
    "            header = ' '.join(clnd_sntc[(i*no_sntcs):((i+1)*no_sntcs)])\n",
    "            grpd_sntc.append(header)\n",
    "\n",
    "            # check if remaining length is less than the desired number of group of sentences\n",
    "            if (((len(clnd_sntc) - ((i+1)*no_sntcs)) < no_sntcs) and ((len(clnd_sntc) - ((i+1) * no_sntcs)) != 0)):\n",
    "\n",
    "                # append remaining sentences\n",
    "                header = ' '.join(clnd_sntc[((i+1)*no_sntcs):])\n",
    "                grpd_sntc.append(header)\n",
    "            else:\n",
    "                pass\n",
    "    else:\n",
    "        # return all sentence as 1 group because total number of sentence is not up to desired number of group of sentences\n",
    "        header = ' '.join(clnd_sntc)\n",
    "        grpd_sntc.append(header)\n",
    "\n",
    "    return grpd_sntc\n",
    "\n",
    "def create_df(list_of_texts):\n",
    "    '''\n",
    "    Function to create dataframe from the series of list of dictionaries.\n",
    "    '''\n",
    "    master_list = list(list_of_texts)\n",
    "\n",
    "    df = pd.DataFrame(master_list, columns=['texts'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filing(filing_ticker, filing_year):\n",
    "    # debugging\n",
    "    print('Getting your File')\n",
    "\n",
    "    # Generate a user agent string for Chrome\n",
    "    user_agent = generate_user_agent(navigator='chrome')\n",
    "\n",
    "    lookup_headers = {\n",
    "        \"referer\": \"https://sec-api.io\",\n",
    "        \"user-agent\": user_agent\n",
    "    }\n",
    "\n",
    "    filing_ticker = str(filing_ticker)\n",
    "    filing_year = int(filing_year)\n",
    "    file_link = str()\n",
    "    company_name = str()\n",
    "    company_ticker = str()\n",
    "    filing_id = str()\n",
    "    data = {\n",
    "            \"query\": {\"query_string\": {\n",
    "                                        \"query\": \"formType:\\\"10-K\\\" AND ticker:(\" + filing_ticker + \") AND filedAt:[\" + str(\n",
    "                                        filing_year) + \"-01-01 TO \" + str(filing_year+1) + \"-01-01] AND documentFormatFiles.type:*21*\"\n",
    "                                        }\n",
    "                    }, \"sort\": [{\n",
    "                                    \"filedAt\": {\"order\": \"desc\"}\n",
    "                                    }]}\n",
    "\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"https://api.sec-api.io/\", headers=lookup_headers, json=data, timeout=10)\n",
    "    except requests.exceptions.Timeout:\n",
    "        print('The request timed out')\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        parsed_json = json.loads(response.text)\n",
    "        hits = parsed_json['total']['value']\n",
    "        if hits > 0:\n",
    "            company_name = parsed_json['filings'][0]['companyName']\n",
    "            company_ticker = parsed_json['filings'][0]['ticker']\n",
    "            examine_link = parsed_json['filings'][0]['linkToFilingDetails']\n",
    "            filing_id = parsed_json['filings'][0]['id']\n",
    "            if examine_link.find('ix?doc=/') != -1:\n",
    "                file_link = examine_link.replace('ix?doc=/', '')\n",
    "            else:\n",
    "                file_link = examine_link\n",
    "        else:\n",
    "            print('No hits')\n",
    "            return \"\"\" <p style=\"text-align: left; font-size: 12px; color: gray; font-style: italic;\"> The file you're looking for doesn't exist yet. </p> \"\"\"\n",
    "    else:\n",
    "        print(response.status_code)\n",
    "\n",
    "    # getting the html content of the 10-K filing and removing any image content and table content\n",
    "\n",
    "    html_to_pdf_retries = 0\n",
    "    get_page_headers = {\"user-agent\": user_agent}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(file_link, headers=get_page_headers, timeout=10)\n",
    "    except requests.exceptions.Timeout:\n",
    "        print('The request timed out')\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        html_without_images = re.sub(r'<img.*?>', '', html)\n",
    "        html_without_tables = re.sub(r'<table.*?>.*?</table>', '', html_without_images)\n",
    "        print(response.status_code)\n",
    "    else:\n",
    "        print(response.status_code)\n",
    "\n",
    "    #####################################################\n",
    "    # changed html_without_tables to html_without_images\n",
    "    pdfkit.from_string(html_without_images, 'output.pdf', options={\"enable-local-file-access\": \"\"})\n",
    "\n",
    "    PDF_read = extract_text('output.pdf')\n",
    "    e_PDF_read = PDF_read.replace('\\n\\n', ' ').replace('\\n', ' ')\n",
    "    e_PDF_read = re.sub(r'\\s+', ' ', e_PDF_read)\n",
    "\n",
    "    # grouped_sentences = split_into_sentences(concatenated_output)\n",
    "    grouped_sentences = split_into_sentences(e_PDF_read)\n",
    "    df_texts = create_df(grouped_sentences)\n",
    "\n",
    "    def create_context(content):\n",
    "        '''\n",
    "        Function to create context from the dataset.\n",
    "        '''\n",
    "        context = 'Company: ' + company_name + \\\n",
    "            ' (' + company_ticker + ')' + '\\n' + content['texts']\n",
    "        return context\n",
    "\n",
    "    # creating context using the company_name and new_text column\n",
    "    df_texts['context'] = df_texts.apply(create_context, axis=1)\n",
    "\n",
    "    # creating context using the company_name and new_text column\n",
    "    # df_texts['embedding'] = df_texts['context'].progress_apply(content_embedding, model_name=mymodel)\n",
    "    df_texts['filing_id'] = filing_id\n",
    "    df_texts['company_name'] = company_name\n",
    "    df_texts['ticker'] = company_ticker\n",
    "    df_texts['year_of_filing'] = filing_year\n",
    "    df_texts.drop(columns=['texts'], inplace=True)\n",
    "\n",
    "    # merge the new dataframe with the existing dataframe\n",
    "    init_data = pd.read_parquet('data.parquet')\n",
    "    merge_df = pd.concat([init_data, df_texts], ignore_index=True)\n",
    "    merge_df.to_parquet('data.parquet', compression='gzip')\n",
    "\n",
    "    return \"\"\" <p style=\"text-align: left; font-size: 12px; color: gray; font-style: italic;\"> Filing parsed. </p> \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['filing_id', 'ticker', 'year_of_filing', 'company_name', 'context'])\n",
    "df.to_parquet('data.parquet', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the get filing function using different tickers and years\n",
    "tickers = ['AAPL', 'MSFT', 'AMZN', 'NFLX']\n",
    "years = [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
    "for ticker in tickers:\n",
    "    for year in years:\n",
    "        get_filing(ticker, year)\n",
    "        print(ticker, year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filing_id</th>\n",
       "      <th>ticker</th>\n",
       "      <th>year_of_filing</th>\n",
       "      <th>company_name</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b5c5243ad175f6c2580d720e74e2aed1</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>2016</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>Company: Alphabet Inc. (GOOG)\\n10-K 1 goog10-k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b5c5243ad175f6c2580d720e74e2aed1</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>2016</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>Company: Alphabet Inc. (GOOG)\\nYes ý Yes ¨ No ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b5c5243ad175f6c2580d720e74e2aed1</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>2016</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>Company: Alphabet Inc. (GOOG)\\nGoogle Inc. Yes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b5c5243ad175f6c2580d720e74e2aed1</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>2016</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>Company: Alphabet Inc. (GOOG)\\nYes ý Yes ý No ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b5c5243ad175f6c2580d720e74e2aed1</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>2016</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>Company: Alphabet Inc. (GOOG)\\nGoogle Inc. Lar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          filing_id ticker  year_of_filing   company_name  \\\n",
       "0  b5c5243ad175f6c2580d720e74e2aed1   GOOG            2016  Alphabet Inc.   \n",
       "1  b5c5243ad175f6c2580d720e74e2aed1   GOOG            2016  Alphabet Inc.   \n",
       "2  b5c5243ad175f6c2580d720e74e2aed1   GOOG            2016  Alphabet Inc.   \n",
       "3  b5c5243ad175f6c2580d720e74e2aed1   GOOG            2016  Alphabet Inc.   \n",
       "4  b5c5243ad175f6c2580d720e74e2aed1   GOOG            2016  Alphabet Inc.   \n",
       "\n",
       "                                             context  \n",
       "0  Company: Alphabet Inc. (GOOG)\\n10-K 1 goog10-k...  \n",
       "1  Company: Alphabet Inc. (GOOG)\\nYes ý Yes ¨ No ...  \n",
       "2  Company: Alphabet Inc. (GOOG)\\nGoogle Inc. Yes...  \n",
       "3  Company: Alphabet Inc. (GOOG)\\nYes ý Yes ý No ...  \n",
       "4  Company: Alphabet Inc. (GOOG)\\nGoogle Inc. Lar...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = pd.read_parquet('data.parquet')\n",
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15064, 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15064/15064 [6:46:55<00:00,  1.62s/it]  \n"
     ]
    }
   ],
   "source": [
    "t['embedding'] = t['context'].progress_apply(content_embedding, model_name=mymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filing_id</th>\n",
       "      <th>ticker</th>\n",
       "      <th>year_of_filing</th>\n",
       "      <th>company_name</th>\n",
       "      <th>context</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b5c5243ad175f6c2580d720e74e2aed1</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>2016</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>Company: Alphabet Inc. (GOOG)\\n10-K 1 goog10-k...</td>\n",
       "      <td>[-0.062086843, -0.19040565, -0.34217635, 0.019...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b5c5243ad175f6c2580d720e74e2aed1</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>2016</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>Company: Alphabet Inc. (GOOG)\\nYes ý Yes ¨ No ...</td>\n",
       "      <td>[-0.06756891, -0.11042685, -0.30150792, -0.147...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b5c5243ad175f6c2580d720e74e2aed1</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>2016</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>Company: Alphabet Inc. (GOOG)\\nGoogle Inc. Yes...</td>\n",
       "      <td>[0.164681, -0.3119648, -0.32115456, -0.1062936...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b5c5243ad175f6c2580d720e74e2aed1</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>2016</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>Company: Alphabet Inc. (GOOG)\\nYes ý Yes ý No ...</td>\n",
       "      <td>[-0.019733991, -0.41353232, -0.31599152, -0.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b5c5243ad175f6c2580d720e74e2aed1</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>2016</td>\n",
       "      <td>Alphabet Inc.</td>\n",
       "      <td>Company: Alphabet Inc. (GOOG)\\nGoogle Inc. Lar...</td>\n",
       "      <td>[-0.14395475, -0.5422194, -0.30889645, 0.01593...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          filing_id ticker  year_of_filing   company_name  \\\n",
       "0  b5c5243ad175f6c2580d720e74e2aed1   GOOG            2016  Alphabet Inc.   \n",
       "1  b5c5243ad175f6c2580d720e74e2aed1   GOOG            2016  Alphabet Inc.   \n",
       "2  b5c5243ad175f6c2580d720e74e2aed1   GOOG            2016  Alphabet Inc.   \n",
       "3  b5c5243ad175f6c2580d720e74e2aed1   GOOG            2016  Alphabet Inc.   \n",
       "4  b5c5243ad175f6c2580d720e74e2aed1   GOOG            2016  Alphabet Inc.   \n",
       "\n",
       "                                             context  \\\n",
       "0  Company: Alphabet Inc. (GOOG)\\n10-K 1 goog10-k...   \n",
       "1  Company: Alphabet Inc. (GOOG)\\nYes ý Yes ¨ No ...   \n",
       "2  Company: Alphabet Inc. (GOOG)\\nGoogle Inc. Yes...   \n",
       "3  Company: Alphabet Inc. (GOOG)\\nYes ý Yes ý No ...   \n",
       "4  Company: Alphabet Inc. (GOOG)\\nGoogle Inc. Lar...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.062086843, -0.19040565, -0.34217635, 0.019...  \n",
       "1  [-0.06756891, -0.11042685, -0.30150792, -0.147...  \n",
       "2  [0.164681, -0.3119648, -0.32115456, -0.1062936...  \n",
       "3  [-0.019733991, -0.41353232, -0.31599152, -0.10...  \n",
       "4  [-0.14395475, -0.5422194, -0.30889645, 0.01593...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.to_parquet('data copy.parquet', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
